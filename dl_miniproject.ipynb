{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DemoySegment/dl-miniproject-resnet/blob/main/dl_miniproject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KDPCtreRsDjn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchsummary\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as functional\n",
        "import torchvision.models as models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "G8HqCmimo_HB"
      },
      "outputs": [],
      "source": [
        "# output_size = (input_size + 2*padding - kernel)/stride + 1 \n",
        "class BuildingBlock(nn.Module):\n",
        "   \n",
        "    def __init__(self, in_channels, intermediate_channels, identity_downsample=None, stride=1, expansion=1):\n",
        "      \"\"\"\n",
        "      This class is for building a resnet block. In each block various \n",
        "      convolution layers will be connected to each other with a batctnorm layer and a relu activation between.\n",
        "      Skip connection will be built between the input of the first layer and the input of the last layer, \n",
        "      that is to add the input of the block to the output of the last batctnorm layer.\n",
        "      Size of the two inputs of skip connection should be pay attention to.\n",
        "\n",
        "      :param in_channels: the number of input channels of the whole block. Since block will repeat several times, \n",
        "      lets say a block with with a input channels of 64 and output channels of 128, the next time going\n",
        "      through the block need a input channels of 128.\n",
        "\n",
        "      :param intermediate_channels: the number of output channels of conv layers in the block. \n",
        "      Since channels always expand, the output channels of the block will be the expansion * intermediate_channels.\n",
        "\n",
        "      :param identity_downsample: a model to deal with skip connection problem. this model should have a conv layer and\n",
        "      a batchnorm layer. In the next iteration of same block, the input channels may not be consist with the output of the \n",
        "      last batchnorm output, therefore we need the parameter to help change x's channels.\n",
        "      :type identity_downsample: nn.Module\n",
        "\n",
        "      :paran stride: if stride>1 for one conv layer in each same block in iteration, then the size of the images will be \n",
        "      decreased for block_num times, which is not what we want. Therefore, for iterations of the the same block, only one layer\n",
        "      in one of the block will have a stride that reduce the size of the image.\n",
        "      \"\"\"\n",
        "\n",
        "      super().__init__()\n",
        "      \n",
        "      #expansion rate, the output channels of the block will be the expansion * intermediate_channels\n",
        "      self.expansion = expansion\n",
        "      self.conv1 = nn.Conv2d(\n",
        "          in_channels,\n",
        "          intermediate_channels,\n",
        "          kernel_size=3,\n",
        "          stride=1,\n",
        "          padding=1,\n",
        "          bias=False,\n",
        "      )\n",
        "      self.bn1 = nn.BatchNorm2d(intermediate_channels)\n",
        "      self.conv2 = nn.Conv2d(\n",
        "          intermediate_channels,\n",
        "          intermediate_channels * self.expansion,\n",
        "          kernel_size=3,\n",
        "          stride=stride,\n",
        "          padding=1,\n",
        "          bias=False,\n",
        "      )\n",
        "      self.bn2 = nn.BatchNorm2d(intermediate_channels * self.expansion)\n",
        "      self.relu = nn.ReLU()\n",
        "      self.identity_downsample = identity_downsample\n",
        "      self.stride = stride\n",
        "      self.in_channels = in_channels\n",
        "      self.intermediate_channels = intermediate_channels\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x.clone()\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "\n",
        "        if self.identity_downsample is not None:\n",
        "            identity = self.identity_downsample(identity)\n",
        "\n",
        "        x += identity\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, layerNums, image_channels, start_channels, num_classes):\n",
        "        super(ResNet, self).__init__()\n",
        "        # head layers\n",
        "        self.in_channels = start_channels\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            image_channels, self.in_channels, kernel_size=7, stride=2, padding=3, bias=False\n",
        "        )\n",
        "        self.bn1 = nn.BatchNorm2d(self.in_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        # recursion block layers\n",
        "        # Essentially the entire ResNet architecture are in these 4 lines below\n",
        "        self.layer1, self.in_channels = self._make_block(\n",
        "            BuildingBlock, layerNums[0], intermediate_channels=64, in_channels=self.in_channels, stride=1\n",
        "        )\n",
        "        self.layer2, self.in_channels = self._make_block(\n",
        "            BuildingBlock, layerNums[1], intermediate_channels=128, in_channels=self.in_channels, stride=2\n",
        "        )\n",
        "        self.layer3, self.in_channels = self._make_block(\n",
        "            BuildingBlock, layerNums[2], intermediate_channels=256, in_channels=self.in_channels, stride=2\n",
        "        )\n",
        "        self.layer4, self.in_channels = self._make_block(\n",
        "            BuildingBlock, layerNums[3], intermediate_channels=512, in_channels=self.in_channels, stride=2\n",
        "        )\n",
        "\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512, num_classes)\n",
        "\n",
        "        self.layerNums = layerNums\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        \n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = self.fc(x)\n",
        "        #x = functional.softmax(x, dim=0)\n",
        "        return x\n",
        "\n",
        "    # for resnet18, expansion === 1\n",
        "    def _make_block(self, block, num_layers, intermediate_channels, in_channels, stride, expansion=1):\n",
        "        identity_downsample = None\n",
        "        layers = []\n",
        "\n",
        "        # Either if we half the input space for ex, 56x56 -> 28x28 (stride=2), or channels changes\n",
        "        # we need to adapt the Identity (skip connection) so it will be able to be added\n",
        "        # to the layer that's ahead\n",
        "        # it is used at the end of first iteration of each block\n",
        "        if stride != 1 or in_channels != intermediate_channels*expansion:\n",
        "          identity_downsample = nn.Sequential(\n",
        "                  nn.Conv2d(\n",
        "                      in_channels,\n",
        "                      intermediate_channels*expansion,\n",
        "                      kernel_size=1,\n",
        "                      stride=stride,\n",
        "                      bias=False,\n",
        "                  ),\n",
        "                  nn.BatchNorm2d(intermediate_channels*expansion),\n",
        "              )\n",
        "\n",
        "        layers.append(\n",
        "            block(in_channels, intermediate_channels, stride=stride, identity_downsample=identity_downsample, expansion=expansion)\n",
        "        )\n",
        "\n",
        "       \n",
        "        in_channels = intermediate_channels*expansion\n",
        "\n",
        "        # For example for first resnet layer: 256 will be mapped to 64 as intermediate layer,\n",
        "        # then finally back to 256. Hence no identity downsample is needed, since stride = 1,\n",
        "        # and also same amount of channels.\n",
        "        for i in range(num_layers - 1):\n",
        "            layers.append(block(in_channels, intermediate_channels, expansion=expansion))\n",
        "        \n",
        "        return nn.Sequential(*layers), in_channels\n",
        "    \n",
        "    def to_string(self):\n",
        "      print('current model status:')\n",
        "      print('parameter numbers: {}'.format(sum(p.numel() for p in self.parameters() if p.requires_grad)))\n",
        "      print('block numbers: {}'.format(self.layerNums))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-8YnQcc6pEaG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66ccb0de-2175-4157-f252-a7dbf608984b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 16, 16]           4,704\n",
            "       BatchNorm2d-2           [-1, 32, 16, 16]              64\n",
            "              ReLU-3           [-1, 32, 16, 16]               0\n",
            "         MaxPool2d-4             [-1, 32, 8, 8]               0\n",
            "            Conv2d-5             [-1, 64, 8, 8]          18,432\n",
            "       BatchNorm2d-6             [-1, 64, 8, 8]             128\n",
            "              ReLU-7             [-1, 64, 8, 8]               0\n",
            "            Conv2d-8             [-1, 64, 8, 8]          36,864\n",
            "       BatchNorm2d-9             [-1, 64, 8, 8]             128\n",
            "           Conv2d-10             [-1, 64, 8, 8]           2,048\n",
            "      BatchNorm2d-11             [-1, 64, 8, 8]             128\n",
            "             ReLU-12             [-1, 64, 8, 8]               0\n",
            "    BuildingBlock-13             [-1, 64, 8, 8]               0\n",
            "           Conv2d-14             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-15             [-1, 64, 8, 8]             128\n",
            "             ReLU-16             [-1, 64, 8, 8]               0\n",
            "           Conv2d-17             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-18             [-1, 64, 8, 8]             128\n",
            "             ReLU-19             [-1, 64, 8, 8]               0\n",
            "    BuildingBlock-20             [-1, 64, 8, 8]               0\n",
            "           Conv2d-21            [-1, 128, 8, 8]          73,728\n",
            "      BatchNorm2d-22            [-1, 128, 8, 8]             256\n",
            "             ReLU-23            [-1, 128, 8, 8]               0\n",
            "           Conv2d-24            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-25            [-1, 128, 4, 4]             256\n",
            "           Conv2d-26            [-1, 128, 4, 4]           8,192\n",
            "      BatchNorm2d-27            [-1, 128, 4, 4]             256\n",
            "             ReLU-28            [-1, 128, 4, 4]               0\n",
            "    BuildingBlock-29            [-1, 128, 4, 4]               0\n",
            "           Conv2d-30            [-1, 256, 4, 4]         294,912\n",
            "      BatchNorm2d-31            [-1, 256, 4, 4]             512\n",
            "             ReLU-32            [-1, 256, 4, 4]               0\n",
            "           Conv2d-33            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-34            [-1, 256, 2, 2]             512\n",
            "           Conv2d-35            [-1, 256, 2, 2]          32,768\n",
            "      BatchNorm2d-36            [-1, 256, 2, 2]             512\n",
            "             ReLU-37            [-1, 256, 2, 2]               0\n",
            "    BuildingBlock-38            [-1, 256, 2, 2]               0\n",
            "           Conv2d-39            [-1, 512, 2, 2]       1,179,648\n",
            "      BatchNorm2d-40            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-41            [-1, 512, 2, 2]               0\n",
            "           Conv2d-42            [-1, 512, 1, 1]       2,359,296\n",
            "      BatchNorm2d-43            [-1, 512, 1, 1]           1,024\n",
            "           Conv2d-44            [-1, 512, 1, 1]         131,072\n",
            "      BatchNorm2d-45            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-46            [-1, 512, 1, 1]               0\n",
            "    BuildingBlock-47            [-1, 512, 1, 1]               0\n",
            "AdaptiveAvgPool2d-48            [-1, 512, 1, 1]               0\n",
            "           Linear-49                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 4,963,882\n",
            "Trainable params: 4,963,882\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 1.20\n",
            "Params size (MB): 18.94\n",
            "Estimated Total Size (MB): 20.15\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = ResNet(BuildingBlock, [2,1,1,1], 3, 32, 10)\n",
        "model = model.to(device)\n",
        "torchsummary.summary(model, input_size=(3, 32, 32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yMYnIkQ2xGU5"
      },
      "outputs": [],
      "source": [
        "def accuracy(y_pred, y):\n",
        "  predict = torch.argmax(y_pred, dim=1)\n",
        "  acc = torch.sum(predict == y) / y.shape[0]\n",
        "  return acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8i2h32KQw5d4"
      },
      "outputs": [],
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    #set the model in training mode\n",
        "    model.train()\n",
        "\n",
        "    for(x, y) in iterator:\n",
        "      x = x.to(device)\n",
        "      y = y.to(device)\n",
        "\n",
        "      y_pred = model(x)\n",
        "      \n",
        "      loss = criterion(y_pred, y)\n",
        "      acc = accuracy(y_pred, y)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      \n",
        "      epoch_loss += loss\n",
        "      epoch_acc += acc\n",
        "      \n",
        "\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GpXNbq0uxR5j"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    #set the model in evaluation mode\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for(x, y) in iterator:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        y_pred = model(x)\n",
        "        loss = criterion(y_pred, y)\n",
        "        acc = accuracy(y_pred, y)\n",
        "        \n",
        "        epoch_loss += loss\n",
        "        epoch_acc += acc\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_epoches(epoch_num, model, optimizer, criterion, trainloader, testloader):\n",
        "  best_valid_acc = float(0)\n",
        "  print(\"start running\")\n",
        "  for epoch in range(N_EPOCHS):\n",
        "      print(' --epoch {}'.format(epoch))\n",
        "      print(\" --start training--\")\n",
        "      train_loss, train_acc = train(model, trainloader, optimizer, criterion)\n",
        "      print(\" --start validing--\")\n",
        "      valid_loss, valid_acc = evaluate(model, testloader, criterion)\n",
        "      if valid_acc > best_valid_acc:\n",
        "        best_valid_acc = valid_acc\n",
        "\n",
        "      \n",
        "      print(f'  \\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "      print(f'  \\t Val. Loss: {valid_loss:.3f} |  Val Acc: {valid_acc*100:.2f}%')\n",
        "      print(f'  Current best Val Acc: {best_valid_acc}')\n",
        "      torch.cuda.empty_cache()\n",
        "  print(\"--end running\")\n",
        "  return best_valid_acc"
      ],
      "metadata": {
        "id": "DiLeiZtdgn8x"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ovstXFFwvm1V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6feda1f-3be3-4668-a079-ce80f03f62de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------lr=0.0010000000474974513, batch_size=64, start-------------\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "start running\n",
            " --epoch 0\n",
            " --start training--\n",
            " --start validing--\n",
            "  \tTrain Loss: 1.326 | Train Acc: 52.22%\n",
            "  \t Val. Loss: 1.081 |  Val Acc: 61.70%\n",
            "  Current best Val Acc: 0.6170382499694824\n",
            " --epoch 1\n",
            " --start training--\n",
            " --start validing--\n",
            "  \tTrain Loss: 0.965 | Train Acc: 65.90%\n",
            "  \t Val. Loss: 0.896 |  Val Acc: 68.47%\n",
            "  Current best Val Acc: 0.6847133636474609\n",
            " --epoch 2\n",
            " --start training--\n",
            " --start validing--\n",
            "  \tTrain Loss: 0.796 | Train Acc: 72.00%\n",
            "  \t Val. Loss: 0.808 |  Val Acc: 71.79%\n",
            "  Current best Val Acc: 0.7178543210029602\n",
            " --epoch 3\n",
            " --start training--\n",
            " --start validing--\n",
            "  \tTrain Loss: 0.679 | Train Acc: 76.32%\n",
            "  \t Val. Loss: 0.753 |  Val Acc: 73.96%\n",
            "  Current best Val Acc: 0.7396497130393982\n",
            " --epoch 4\n",
            " --start training--\n",
            " --start validing--\n",
            "  \tTrain Loss: 0.580 | Train Acc: 79.69%\n",
            "  \t Val. Loss: 0.720 |  Val Acc: 75.79%\n",
            "  Current best Val Acc: 0.7578622698783875\n",
            " --epoch 5\n",
            " --start training--\n",
            " --start validing--\n",
            "  \tTrain Loss: 0.491 | Train Acc: 82.75%\n",
            "  \t Val. Loss: 0.816 |  Val Acc: 74.28%\n",
            "  Current best Val Acc: 0.7578622698783875\n",
            " --epoch 6\n",
            " --start training--\n",
            " --start validing--\n",
            "  \tTrain Loss: 0.412 | Train Acc: 85.66%\n",
            "  \t Val. Loss: 0.802 |  Val Acc: 74.75%\n",
            "  Current best Val Acc: 0.7578622698783875\n",
            " --epoch 7\n",
            " --start training--\n",
            " --start validing--\n",
            "  \tTrain Loss: 0.332 | Train Acc: 88.34%\n",
            "  \t Val. Loss: 0.795 |  Val Acc: 75.97%\n",
            "  Current best Val Acc: 0.7596536874771118\n",
            " --epoch 8\n",
            " --start training--\n",
            " --start validing--\n",
            "  \tTrain Loss: 0.270 | Train Acc: 90.56%\n",
            "  \t Val. Loss: 0.888 |  Val Acc: 75.17%\n",
            "  Current best Val Acc: 0.7596536874771118\n",
            " --epoch 9\n",
            " --start training--\n",
            " --start validing--\n",
            "  \tTrain Loss: 0.214 | Train Acc: 92.38%\n",
            "  \t Val. Loss: 0.865 |  Val Acc: 77.29%\n",
            "  Current best Val Acc: 0.7728901505470276\n",
            "--end running\n",
            "--------------lr=0.0010000000474974513, batch_size=64, result=0.7728901505470276-------------\n",
            "--------------lr=0.0010000000474974513, batch_size=128, start-------------\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "start running\n",
            " --epoch 0\n",
            " --start training--\n",
            " --start validing--\n",
            "  \tTrain Loss: 1.320 | Train Acc: 52.49%\n",
            "  \t Val. Loss: 1.193 |  Val Acc: 58.74%\n",
            "  Current best Val Acc: 0.5874208807945251\n",
            " --epoch 1\n",
            " --start training--\n",
            " --start validing--\n",
            "  \tTrain Loss: 0.960 | Train Acc: 66.00%\n",
            "  \t Val. Loss: 1.034 |  Val Acc: 63.72%\n",
            "  Current best Val Acc: 0.6371637582778931\n",
            " --epoch 2\n",
            " --start training--\n",
            " --start validing--\n",
            "  \tTrain Loss: 0.789 | Train Acc: 72.27%\n",
            "  \t Val. Loss: 0.849 |  Val Acc: 70.34%\n",
            "  Current best Val Acc: 0.7034217119216919\n",
            " --epoch 3\n",
            " --start training--\n",
            " --start validing--\n",
            "  \tTrain Loss: 0.662 | Train Acc: 76.73%\n",
            "  \t Val. Loss: 0.806 |  Val Acc: 71.56%\n",
            "  Current best Val Acc: 0.715585470199585\n",
            " --epoch 4\n",
            " --start training--\n",
            " --start validing--\n",
            "  \tTrain Loss: 0.559 | Train Acc: 80.32%\n",
            "  \t Val. Loss: 0.775 |  Val Acc: 73.81%\n",
            "  Current best Val Acc: 0.7381329536437988\n",
            " --epoch 5\n",
            " --start training--\n",
            " --start validing--\n",
            "  \tTrain Loss: 0.472 | Train Acc: 83.53%\n",
            "  \t Val. Loss: 0.788 |  Val Acc: 74.42%\n",
            "  Current best Val Acc: 0.7441653609275818\n",
            " --epoch 6\n",
            " --start training--\n",
            " --start validing--\n",
            "  \tTrain Loss: 0.391 | Train Acc: 86.29%\n",
            "  \t Val. Loss: 0.821 |  Val Acc: 74.39%\n",
            "  Current best Val Acc: 0.7441653609275818\n",
            " --epoch 7\n",
            " --start training--\n",
            " --start validing--\n",
            "  \tTrain Loss: 0.323 | Train Acc: 88.40%\n",
            "  \t Val. Loss: 0.847 |  Val Acc: 74.69%\n",
            "  Current best Val Acc: 0.7469343543052673\n",
            " --epoch 8\n",
            " --start training--\n",
            " --start validing--\n",
            "  \tTrain Loss: 0.248 | Train Acc: 91.23%\n",
            "  \t Val. Loss: 0.929 |  Val Acc: 74.09%\n",
            "  Current best Val Acc: 0.7469343543052673\n",
            " --epoch 9\n",
            " --start training--\n",
            " --start validing--\n",
            "  \tTrain Loss: 0.197 | Train Acc: 92.76%\n",
            "  \t Val. Loss: 0.983 |  Val Acc: 74.91%\n",
            "  Current best Val Acc: 0.7491099834442139\n",
            "--end running\n",
            "--------------lr=0.0010000000474974513, batch_size=128, result=0.7491099834442139-------------\n",
            "--------------lr=0.0010000000474974513, batch_size=256, start-------------\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "start running\n",
            " --epoch 0\n",
            " --start training--\n",
            " --start validing--\n",
            "  \tTrain Loss: 1.322 | Train Acc: 52.24%\n",
            "  \t Val. Loss: 1.179 |  Val Acc: 58.56%\n",
            "  Current best Val Acc: 0.585644543170929\n",
            " --epoch 1\n",
            " --start training--\n",
            " --start validing--\n",
            "  \tTrain Loss: 0.951 | Train Acc: 65.98%\n",
            "  \t Val. Loss: 0.954 |  Val Acc: 66.42%\n",
            "  Current best Val Acc: 0.6641601920127869\n",
            " --epoch 2\n",
            " --start training--\n"
          ]
        }
      ],
      "source": [
        "N_EPOCHS = 10\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "criterion = criterion.to(device)\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "lr_candidates = torch.linspace(0.001, 0.1, 30)\n",
        "\n",
        "batch_size_candidates = [64, 128, 256]\n",
        "\n",
        "best_result = (0,0,0)\n",
        "for lr in lr_candidates:\n",
        "  for batch_size in batch_size_candidates:\n",
        "    model = ResNet(BuildingBlock, [2,1,1,1], 3, 32, 10)\n",
        "    model = model.to(device)\n",
        "    print(\"--------------lr={}, batch_size={}, start-------------\".format(lr, batch_size))\n",
        "    # optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr.item())\n",
        "\n",
        "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "\n",
        "    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    result = run_epoches(N_EPOCHS, model, optimizer, criterion, trainloader, testloader)\n",
        "    print(\"--------------lr={}, batch_size={}, result={}-------------\".format(lr, batch_size, result))\n",
        "    if result > best_result[2]:\n",
        "      best_result = (lr, batch_size, result)\n",
        "    \n",
        "print(best_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5q7XXojEsw1s"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 128\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYM-HUdKxcAR"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOi8AGbHRQGJjrW4H1XuPWD",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}